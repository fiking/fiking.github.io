---
title: >-
  Adaption-Optimization-for-SELF:Reconciling-high-performance-with-exploratory-programming
  论文翻译
tags:
  - virtual machine
categories:
  - dissertation translation
  - virtual machine
date: 2021-08-28 22:02:27
description:
---

# 前言

  为了增加虚拟机方面的理论知识，开始了虚拟机相关的论文翻译和学习。先制定个伟大的目标，前期每周一篇翻译，后续在根据学习情况进行论文的总结精炼。

  开篇文章为 **Urs Hölzle** 1994年的博士论文《Adaption Optimization for SELF: Reconciling high performance with exploratory programming》。根据网上资料此文章是 OpenJDK、V8的主要思想来源，所以优先进行阅读。

 <!-- more -->

# 翻译

## 论文题目

SELF 自适应优化：探索性编程与高性能共存

## 作者

Urs Hölzle

## 时间

1994年八月

## 正文

### 摘要

面向对象语言带来许多的益处，其中的抽象性，可以让程序员隐藏来自对象客户端的对象实现细节。不幸的是，在跨越抽象边界如频繁的过程调用中总是伴随着巨大的运行时开销。因此，尽管频繁的使用抽象是这类语言的设计目的，但这是不切实际的，因为，它会导致程序非常低效。

激进的编译器优化会降低抽象的开销。但是优化编译器带来长的编译时间会延长编程环境反馈程序变化的时间。此外，优化也会与源码级别的调试冲突。因此，程序员面临一个两难的选择，不得不在高效的抽象和高效的编程环境之间进行选择。本论文会展示如何通过延迟编译调和这个看起来是矛盾的目标。

融合四个新的技术来达成高性能和高响应：

- ***Type feedback***  通过允许编译器基于获取自运行时系统的信息内联消息发送（message send）来取得高性能。平均来说，在有类型反馈的SELF系统上，程序运行会比在之前的 SELF 系统快1.5倍；而与商业的 Smalltalk 实现对比，两个中型的 benchmark 会快三倍。这个水平的性能是从一个比之前 SELF 编译器更简单和更快速的编译器上取得的。
- ***Adaptive optimization*** 在取得高响应的同时不会牺牲性能，通过使用非优化编译器生成初始代码，同时在运行期间使用优化编译器重编程序中重度使用的代码部分。在前一代的工作平台上如 SPARCstation-2，50 分钟的交互中有将近200个暂停超过200ms，21个暂停超过了 1 秒。在当代的工作平台上，只有13个暂停超过400ms。
- ***Dynamic deoptimization*** 在需要时通过隐式地重建非优化代码，使得程序员可以远离调试优化过的代码的复杂性。不管一个程序是否被优化过，它都可以被停止，检查和单步调试。比起之前的方法，去优化（deoptimization）支持更多的调试的同时，对于可执行的优化代码添加更少的限制。
- ***Polymorphic inline caching*** 实时生成类型信息序列来加速来自于相同调用位置但具有不同的类型对象的消息发送。更重要的是，它会为优化编译器搜集了具体的类型信息。

具有高性能和良好的交互行为的这些技术，让探索性编程既适用于纯粹面向对象语言，也适用于需要更高最终性能的应用领域；调和了探索性编程，繁多的抽象和高性能。

### 致谢

作者的感谢，暂不翻译。

### 目录列表

暂不翻译。

### 图片列表

暂不翻译。

### 表列表

暂不翻译。

### 1. 引言

面向对象编程越来越流行，因为它让编程更简单了。它允许程序员隐藏来自对象客户端的实现细节，将每个对象放入对应的抽象数据类型中，操作和状态都只能通过消息发送进行访问。延迟绑定极大地提高了抽象数据类型的能力，通过允许相同抽象数据类型的不同实现，在运行时可以实现进行互换。这个互换指的是一段调用某个对象的一个操作的代码并不总是最终会被执行调用的代码：延迟绑定（也叫动态分发）会选择一个操作合适的实现基于对象的准确类型。因为延迟绑定对于面向对象是最基本的，需要高效的实现来支持。

理想状态下，面向对象语言会全部使用延迟绑定的，即使对于实例变量访问这种基础的操作也是一样。越普遍地使用封装和动态分发，最终的代码具有越高的自由度和重用性。但是延迟绑定会带来效率问题。例如，如果所有的实例变量方位都使用消息发送，编译器无法将一个对象的属性x的访问翻译为一个简单的加载指令，因为对象间的x实现可能是不同的。例如，一个笛卡尔点可能只是返回一个实例变量的值，而一个极坐标点会根据半径和角坐标计算x的值然后进行返回。这种变化恰恰是延迟绑定的意义：x的操作与操作的实现（实例变量的访问和计算）的绑定延迟到了运行的时候才做。因此，x的操作必须编译成一个动态分发的调用（也叫间接函数调用或者虚函数调用），从而可以在运行时选择一个合适的实现。这导致了一个周期的指令变成了十个周期的调用。随着源码自由度和重用度的增加会带来显著的运行时开销；从而看起来封装和高效是不能共存的。本文会展示如何平衡两个。

一个相似的效率问题也出现在渴望使用探索性编程环境上。一个探索性编程环境增加了程序员的生产率通过对所有的编程操作给与立即的反馈；零暂停交互允许程序员集中于手上的任务而不被长时间的编译暂停分心。通常来说，系统设计者在探索性编程环境会使用解释器和非优化的编译器。不幸的是，解释器的开销，伴随着动态分发的效率问题，降低了执行性能，因此限制了这种系统的使用。这篇论文描述如何降低动态分发的开销从而保证一个交互探索编程环境的反馈获取。

我们研究的轮子是面向对象语言 SELF。SELF 的纯语义加剧了面向对象语言面临的实现问题：在 SELF，每个单操作（甚至赋值操作）都涉及延迟绑定。因此，这个语言是降低延迟绑定优化的理想测试用例。同样重要的是，SELF是为了探索编程设计的。每个探索编程环境必须提供程序变化之后快速的转化，和局部程序的简单调试，从而增加程序员的生成率。因此，一个这种系统的优化编译器不仅要解决动态分发带来的性能问题，也要适配交互性：编译必须快速和非侵入性的，还有系统必须支持全时间段的全源码调试。

我们为SELF实现了一个系统，工作的贡献有：

- 一个新的优化策略， ***Type Feedback***，允许任意的动态分发调用被内联。在我们为 SELF 做的实现样例中，类型反馈将函数调用降低了四倍同时提高了 70% 的性能比起没有类型反馈的系统。尽管 SELF 和 C++ 是完全不同的语言模型，新的系统使得 SELF 在两个中型的面向对象的程序达到了优化过的C++性能的一半。
- 一个重编译系统，动态重新编译应用的 "hot spots"。这个系统通过一个快速的非优化编译器产生初始化代码，然后通过一个慢的优化编译器重新编译那些时间紧迫的部分代码。引入自适应动态编译戏剧性地提高了 SELF 系统的交互性能，让优化编译和探索性编程环境结合成为了可能。即使在前一代工作平台如 SPARCstation-2，50 分钟的交互中有将近200个暂停超过200ms，21个暂停超过了 1 秒。
- 一个内联缓存的扩展， ***polymorphic inline caching***，可以加速多态   调用点的动态分配调用。此外多态内联缓存可以做为类型反馈的类型信息源，平均提升11%的性能。
- 一个调试系统，动态退优化为全局优化代码提供源码级别的调试。即使优化代码只支持严格的调试，这个系统可以隐藏那些限制，提供全源码级别的调试（例如，单步调试这类调试操作）。

虽然我们的实现基于动态编译，但是本文中大部分的技术不需要它。类型反馈会直接被整合进传统的编译系统（看5.6节），类似于其它的基于 profile 的系统。源码级别的调试可以通过保留编译前的未优化代码到一个分离的文件来实现（看10.5.3）。多态内联只需要一个简单的桩生成器，并不需要全成熟的动态编译。只有5.3节描述的动态编译系统--从本质上而言--才需要动态编译。

本文描述的技术都不仅仅限定于 SELF 语言。就如10.5.3节的讨论，调试系统具有非常大的语言无关性。类型反馈可以优化任何语言的延迟绑定；如和面向对象语言相比，那些有重度使用延迟绑定的非面向对象语言（如，APL的通用操作符，Lisp的通用算术）也会从这种优化中获得收益。最后，任何使用动态编译得系统都可能从自适应编译中获取提高性能和降低编译暂停得收益。

本论文剩余部分，我们会描述这些技术得设计和实现，并且评估它们对于 SELF 系统的性能影响。所有的技术都全部实现并且足够稳定地成为了公共 SELF 发布包的一部分。第二章呈现 SELF 的概述和随后章节描述的工作概述，以及讨论相关工作。第三章讨论如何动态分发可以被运行时系统优化，例如，编译器外。第四章描述非优化的 SELF 编译器和评估它的性能。第五章描述类型反馈如何降低动态分发的开销，第六章描述 SELF 优化编译器的实现。第七章和第八章评估新的 SELF 编译器对于之前SELF系统的性能，对其它语言的性能，以及调查硬件特性对性能的影响。第九章讨论优化编译器怎么对系统交互行为产生影响。第十章描述我们的系统怎样提供全源码级的调试且不影响编译器的优化性能。

如果你非常的匆忙且已经很熟悉之前的 Smalltalk 或者 SELF 的实现，我们建议你可以跳过第二章（简介），然后阅读每一章末尾的总结，加上结论。

143页的词汇表包含了本文大部分重要术语的简短定义。

### 2. 背景和相关工作

这个章节展现本论文的一些背景和相关工作。首先，我们简短的介绍 SELF 语言和它的目标，其次是 SELF 系统的概述。然后，我们的新系统的编译过程，最后我们会回顾相关的工作。

#### 2.1 SELF 语言

SELF 是一个 动态类型，基于原型和面向对象的语言，最初的设计是1986年 David Ungar 和  Randall B. Smith 在 Xerox PARC 做的。想要作为 Smalltalk-80 编译语言的一个备选，SELF尝试最大化程序员在探索性编程环境的生产力通过保持语言的简单性和纯净，而不降低表达能力和扩展性。

SELF 是一种纯粹的面向对象语言：所有的数据都是对象，且所有计算的执行都是通过动态绑定消息发送的（包括所有的实例变量访问，即使在接收者对象里）。因此，SELF合并状态和行为i：语法上，方法调用和变量访问是不区分的--发送者不知道消息是简单数据访问的实现还是方法的实现。于是，所有的代码时表达独立的，因为相同的代码可以被不同结构的对象重复使用，只要这些对象正确实现期望的消息协议。换句话说，SELF支持全抽象数据类型：只有对象的接口是可见的，所有的实现细节如对象的大小和结构都被隐藏，即使代码在对象本身里。

SELF 其它主要的重点如下列表：

- SELF 是动态类型的：程序包含无类型的定义。
- SELF 是基于原型的而不是类。每个对象是自描述的可以被独立改变。除了这种方法的灵活性，基于原型的系统可以避免元类（metaclasses）带来的复杂度。
- SELF 有多继承。多继承设计在这些年经历了一些改变。SELF-87 只有单继承，但是 SELF-90 引入了 优先多继承结合一个新的隐私机制为了更好的封装和一个“发送者路径判定”规则为了消除相同优先级父节点的歧义。最近，钟摆又摆回了简单性：SELF-92 消除了发送者路径判定因为它倾向于隐藏歧义，而 SELF-93 消除了优先级继承和来自语言的隐私。
- 所有的控制结构式用户定义的。例如，SELF没有 **if** 语句。作为替代，控制结构通过消息发送和块（闭包）实现，就像 Smalltalk-80。但是，不同于 Smalltalk-80的是，SELF的实现没有固化任何的控制结构，换句话说，程序员可以改变任何方法（包括那些实现if语句，循环和整型加法的方法）的定义，系统会忠实地反射这些变化。
- 所有的对象是堆分配的且被垃圾回收器自动解除分配。

这些特性被设计来发挥现代计算机的计算能力，使得程序员的生活更简单。例如，表达独立性使得重复使用和重组代码变得简单，但是产生了实现问题，因为每个数据访问都关联了一个消息发送。比起关注最小程序窒执行时间，SELF更关注于最小编程时间。

#### 2.2 SELF系统

SELF系统的实现目标反映了语言：最大化编程生产效率的特点。几个特性为这个目标做出贡献：

- ***Source-level  sematics***。系统的行为总是可以用源语言级别的术语解释。程序员应该从不面对一些如 “segmentation fault"，”arthmetic exception: denormalized float“ 的错误，因为这些错误在缺少对底层实现细节的深入了解是无法解释的，这些实现细节超出了语言的定义因此难以理解。因此，所有的 SELF 原语都是安全的：算术操作测试溢出，数组访问执行下标边界检查等。
- ***Direct execution sematics(interpreter semantics)***。 系统应该总是表现如同直接执行方法源码：任何源码改变都是立即生效的。直接执行语义使得程序员免于担心不得不显式调用编译器和链接器，免于不得不处理编译依赖等枯燥的细节。
- ***Fast turnaround time***。 在做出变化之后，程序员不会因为慢速编译器和链接器而等待；这类的延迟应该尽可以能得短（理想下，只是几分之一秒）。
- ***Efficiency***。最后，程序应该总是有效率的运行不受 SELF纯度的影响：程序员不应该因为选择 SELF 而不选择更传统的语言而受惩罚。

这些目标不是轻易能达成的。特别是，因为强调成为程序员正确的语言而不是成为机器的语言，SELF 是很难实现的有效率的。几个关键的语言特性创造了特别难的问题：

-  由于所有的计算都是由消息发送执行的，在底层实现中调用频率极其高。如果简单和通用的计算，这些在传统的编译器中通常只需要单条指令（如一个实例变量访问或者一个整形加法），都调用动态分发的过程调用，程序将会比传统语言运行慢上许多，即使没有一百的慢。
- 相似的，由于没有内置的控制结构，一个简单的 **for** 循环涉及数十条消息发送和几个块（闭包）的创建。因为控制结构的定义可以被用户改变，编译器不能走捷径地将它们的翻译和手写优化代码模式硬关联在一起。
- 因为总体目标是最大化程序员生产率，系统应该有高频的交互和提供立即的反馈给用户。因此，长的编译暂停（出现在优化编译器中的）是无法接受的，进一步限制了实现者在找寻有效的 SELF 实现的自由。

下面的章节给出当前SELF实现的概述和它是怎样尝试解决上面描述的问题的。在描述基础系统之后，我们会强调新的解决方案，这是这篇文章的主题，以及它们怎么适配已经存在的系统。

##### 2.2.1 实现概述

 SELF 虚拟机有如下几个子系统组成：

- 一个 ***memory system*** 处理分配和垃圾回收。对象被存放在堆中；一个分代的扫描垃圾回收器回收不使用的对象。对象引用通过两个比特位标签标记在每个32位字的低两位上（标签00 是整形，01 是指针，10 是浮点，11是对象头）。所有的对象处理整形和浮点由至少两个字组成：一个字表示header，一个指针指向对象 map。一个 map 描述对象的格式，可以被看成是对象低级别类型。有相同格式的对象共享相同的map，所以对象的布局信息只会被存储一次。为保持语言规定的自描述对象的抽象，map是写时拷贝：l例如，当一个槽被添加到一个对象时，这个对象会得到一个新的map。
- 一个 ***parser***  读取文本描述的对象，以及将其转化为真的对象存储到堆。方法被表示为简单的字节码集合（本质上是，“send"，”push literal“，和”return“）。
- 给予一个消息名和一个接送者，***lookup system***  决定查找的结果，例如，匹配槽。查找首先检查哈希表（代码表）找寻编译过的代码是否存在。如果存在，代码就被执行；否则，系统执行实际的对象查找（如果需要的化遍历接受者的父对象），然后调用编译器生成机器码来执行方法或者数据访问。
- ***compiler***  转换一个方法的字节码为机器码然后存储到***code cache***。 如果代码缓存中已经没有空间给新的编译过的方法，已经存在的方法会被清理来获得空间。代码缓存保存近似 LRU 信息来决定哪个编译过的方法被清理。
- 最后，虚拟机也包含许多的原语，可以被 SELF 程序调用来执行算术计算，I/O，图形绘制等。新的原语可以在运行时被动态链接到系统。

参考[88]，[115]，和[21]包含更多的系统细节。

##### 2.2.2 效率

因为 SELF 的纯语义威胁让程序效率极其低下，许多早期的实现尽力使用编译技术优化 SELF 程序。这些技术中有些是非常成功的：

***Dynamic compilation*** 。 编译器按需动态的翻译源方法成编译过的方法。这意味着没有分离的编译过程，执行和编译是交错的。（SELF 动态编译的使用灵感来自 Deutsch-Schiffman Smalltalk system[44]。）

***Customization***。 定制化允许编译器决定一个方法中许多消息接送者的类型[23]。它利用方法的许多消息是发送给 **self** 的事实来扩展动态编译。编译器根据每个接送者类型为一份源码创建不同版本的编译代码（Figure 2-1）。例如，方法min：源方法计算两个数的最小值，会被创建为两个不同的方法。这个复制允许编译器客制化每个版本到特定的接受者类型。特别是，在编译时知道 self 的类型使得编译器可以内联所有的发送 self。客制化在 SELF 中是非常重要的，因为许多消息是发送给 self，包括实例变量访问，全局变量访问，和许多用户定义的控制类型。

{% if 1 == 1 %} 
  {% asset_img figure_2_1.png title %}
{% else %}
  ![](H:\Blogs\fiking\source\_posts\Adaption-Optimization-for-SELF-Reconciling-high-performance-with-exploratory-programming-论文翻译\figure_2_1.png)

{% endif %}

***Type Prediction***。确定的消息几乎只发送给特定的接受者类型。对于这样的消息，编译器使用最早由 Smalltalk 系统引入的优化[44，132]：它预测接受者的类型基于消息名字并且插入运行时类型检测于消息发送前用于测试期望的接送者类型（Figure 2-2）。类似的优化在 Lisp 系统中被用于优化通用计算。沿着类型测试成功的分支，编译器有关于接受者类型的精确信息可以静态地绑定和内联一个消息的拷贝。类如，现有的 SELF 和 Smalltalk 系统预测 ‘+’ 会被发送给整形 [128，58，44]，因为测量显示 这个类型 90% 的时间会出现 [130]。如果测试的开销是比较低且成功的可能性比较高，则类型预测会提高性能。

{% if 1 == 1 %} 
  {% asset_img figure_2_2.png title %}
{% else %}
  ![](H:\Blogs\fiking\source\_posts\Adaption-Optimization-for-SELF-Reconciling-high-performance-with-exploratory-programming-论文翻译\figure_2_2.png)

{% endif %}

***Splitting*** 是另外一种方法，将一个多态的消息转变为多个分离的单态消息。通过拷贝部分的控制流图 [23，22，24] 避免类型测试。例如，一个对象在 if 语句的一个分支上是一个整形，而在另一个分支上是浮点（Figure 2-3）。如果这个对象是 if 语句之后的消息发送的接收者，编译器可以拷贝这个发送到两个分支。因此在每个分支上都是确定的接受者类型，编译器可以分别内联这两个发送的拷贝。

{% if 1 == 1 %} 
  {% asset_img figure_2_3.png title %}
{% else %}
  ![](H:\Blogs\fiking\source\_posts\Adaption-Optimization-for-SELF-Reconciling-high-performance-with-exploratory-programming-论文翻译\figure_2_3.png)

{% endif %}

合并在一起，这些优化将 SELF的性能提升到合理的水平。举个例子，Chambers 和 Ungar 报告了 SELF 显著地跑赢了 ParcPlace Smalltalk-80 的实现在一个小的类C的整形测试用例集上[26]。

##### 2.2.3 源码级的语义

语言和实现特性的结合确保了所有程序的行为，即使错误的部分，也可以通过源码级别的术语独立理解。语言保证了每个消息发送要么找到一个匹配槽（访问它的数据或者运行它的方法），或者导致一个“message not understood" 的错误。最后，这个级别的唯一错误是查找错误。此外，实现保证了所有的原语是安全的。因为所有的原语会检查它们的操作数和结果，如果操作数无法被执行会以明确的方式失败。例如，所有的整型算术原语检查溢出，数组访问原语检查范围错误。最后，因为 SELF 不允许指针算术和使用垃圾回收，所以系统是指针安全的：不会偶然地复写随机的内存区域或者解引用悬挂指针。这些特性的结合让它更容易找到程序错误。

安全原语让高效实现更难[21]。例如，每个整型加法不得不检查溢出，从让它变慢。更重要的是，整型操作的返回值类型是未知的：所有的原语都有 “故障块” 的参数，如果操作失败，一个消息会被发送给这个参数。然后这个发送的结果会变成原语调用的返回值。例如，当前 SELF 系统的整型的 “+” 方法调用 IntAdd：带有失败块的原语会将失败块参数转化为任意精度的整型然后进行相加。因此表达式 x + y 的精确的返回值类型是未知的，即使 x 和 y 都是已知的整型：没有溢出，返回值会是整型，但是当结果太大而不能被表示为一个机器级别的整数时，结果就会时任意精度的整数。因此，即使 x 和 y 是已知的整数，编译器也无法静态的知道表达式 x + y + 1 的第二个 “+” 会调用整型的加法还是任意精度数的加法。安全原语帮助程序员的同时也潜在地使执行变慢。

##### 2.2.4 直接执行语义

SELF 通过使用动态编译模仿解释器。每当一个没有相关编译过代码的源码方法被调用，编译器会被自动调用生成缺失的代码。反过来，每当用户改变源方法，所有依赖于旧定义的编译过代码会被无效化。为了实现这个系统在源码方法和编译过的方法维持一个依赖链接[71,21]。

因为没有显式的编译和链接步骤，传统的编写-编译-链接-运行循环被简化为一个编写-运行循环。程序可以在运行时被改变，所以应用可以被在线调试而不需要从头开始运行。

#### 2.3 编译过程概述

Figure 2-4 较详细地展示了新的 SELF-93 系统的编译过程。SELF 的方法源码以对象的形式存储到堆上，就像其它的数据对象一样。方法的代码被编码为一个简单栈式机器的一串字节码（“instruction”）。这些字节码可以在解释器上直接执行；但是当前的 SELF 系统从没有这样做。反而，这些字节码总是按需地被翻译为机器码。当一个源码第一次被执行，机器码被实时生成。通常，第一次编译的代码是由“快速但笨"的编译器生成的。未优化的代码是字节码的直接翻译所以相当的慢；章节4 更细节地描述非优化的编译器。

{% if 1 == 1 %} 
  {% asset_img figure_2_4.png title %}
{% else %}
  ![](H:\Blogs\fiking\source\_posts\Adaption-Optimization-for-SELF-Reconciling-high-performance-with-exploratory-programming-论文翻译\figure_2_4.png)

{% endif %}

未优化的代码包含一个调用计数器。每当计数器超过一定的阈值，系统会调用重编译系统来决定是否优化是需要的以及应该重新编译哪些方法。然后重编译系统调用优化编译器。章节5详细的解释了重编译过程，章节6描述优化编译器。

作为我们工作的一部分，我开发了一个新的内联缓存的变种，多态内联缓存（polymorphic inline caches(PICs)）。PICs 不仅加速多态调用点的运行时分配，也为编译器提供接收者类型的值信息。章节3描述PICs怎么工作的，章节5解释了优化编译器怎么利用 PICs 中的类型反馈信息。

在一些例子中，优化方法会再被重新编译。例如，重编译系统可以因为第一次优化后的方法仍然包含许多可以被内联的调用（比如，第一次优化编译的时候没有足够多的类型信息而不能内联）而决定重新编译。一个优化过的方法也会被重新编译当它遇到 “uncommon cases"：编译器可能预测某些场景从不会出现（如，整型溢出）而忽略了这种场景的代码生成。如果这种被忽略的场景刚好出现，原始优化过的方法就会被重新编译，扩展成处理这些特殊场景的代码（章节6.1.4）。

在本文的剩余部分，我们会按通常的顺序讨论系统的每个组件：首先，多态内联（PICs）和非内联编译器，然后重编译系统，最后是优化编译器本身。

#### 2.4 本工作的收益

本文所描述的所有技术都在 SELF-93 系统中实现了，在如下几个方面有了提升：

- ***Higher performance on realistic programs***。通过自动重编译和程序关键性能段的重新优化，我们的优化编译器可以利用运行时收集的信息。这些额外的信息经常使得编译器产生比之前代码更有效率的代码，即使编译器只执行很少的编译时程序分析。例如，DeltaBlue 约束求解器，当前的代码比之前版本的优化编译器产生的代码快三倍（章节7）。
- ***More stable performance***。新的编译器更多的依赖于动态观察到的程序行为和更少的静态分析，因此不太会受到静态分析技术盲点的影响。脆弱的性能是前一代 SELF 编译器的主要问题：小的源文件改变会导致戏剧性的性能损失，因为改变可能会导致一个特别重要的优化失效。例如，Stanford ineger  benchmarks 的一组小改变在前一代 SELF 编译器编译下会减慢 2.8 倍，而在新的编译器下编译只降低 16%（见章节7.4）。
- ***Faster and simpler compilation***。我们的方法依赖于运行时系统的动态反馈而不是使用复杂的静态类型分析技术在更好的运行时性能上有额外的优势。首先，它导致一个简单的编译器（11000 对比 26000 非注释源行代码）。第二，新的编译器比之前的编译器快2.5倍（见9.5节）。对于用户，编译暂停降低了更多（见9.2节）因为系统只是优化一个应用的关键路径。
- ***Support for source-level debugging***。在之前的 SELF 系统，用户可以打印优化程序的栈，但是他们不能在运行的时候改变程序，还有他们也不能执行诸如单步调试等通用的调试手段。我们的新系统提供随时的退优化功能让调试员的工作更简单（见第十章节）。

#### 2.5 相关工作

本节比较 SELF 系统和常见的相关工作；后续章节给出更多的比较细节。

##### 2.5.1 动态编译

SELF 使用动态编译，例如，运行时实时生成代码。动态生成编译代码而不是使用传统的批量式编译的思路源自于快速解释器的需求不断增加；通过编译到本地代码，一些解释器的固定开销（特别是伪指令的解码）可以被避免。例如，假设变量的类型保存不变，Mitchell[97] 建议可以将动态类型解释式程序的一部分转为编译形式。编译过的代码第一次被生成是作为一个表达式解释时的副作用产生的。类似地，线程代码[12]最早被用于消除一些解释过程的固定开销的。

传统上使用解释器或者动态编译器有两个原因：第一，一些语言很难被有效的静态编译，通常是因为独立的源程序没有足够的低级别的类型实现信息来生成高效的代码。第二，一些语言过于强调交互使用因此被实现为解释器而不是慢速编译器。

APL 是一种既难于进行静态编译（因为许多操作是多态的）且强调交互使用的语言。不出意外的话，APL 系统是最早探索动态编译的系统之一。例如，Johnston[80] 描述了一个使用动态编译作为解释的一个高效替代的 APL 系统。这些系统使用的一些机制类似于客制化（如，Guibas and Wyatt[61]）和内联缓存（Saal and Weiss[111]）。

Deutsch 和 Schiffman 在面向对象语言开创性地使用了动态编译。他们的 Smalltalk-80 的实现动态翻译了 Smalltalk 虚拟机定义的字节码到本地机器码并进行缓存供后续使用；Deutsch 和 Schiffman 估计仅仅使用简单的动态编译替换解释就加速了他们的系统 1.6 倍，使用更复杂的编译器则会有将近 2 倍的收益。

Franz[55] 描述了一个在加载时将紧凑的中间代码表示转为机器码的动态编译的变种。就像 Smalltalk ”snapshot“ 中的字节码，中间表示代码是架构独立的，同时，它也尽量是语言独立的（当前的实现只有Oberon支持）。从中间码到机器码的编译是足够快的使得当前加载器与常规加载器相比差异不大。

动态编译除了语言实现之外对于应用也是有用的[82]，它已经在多种方式下被使用。例如，Kessler et al. 用它来实现调试器的快速断点[84]。Pike et al. 通过动态生成最佳代码序列来加速 "bit-blt" 图形原语[103]。在操作系统中，动态编译被用来高效支持细粒度并行[32，105]和消除协议栈的开销[1]，以及动态链接[67]。动态编译也在其它领域被使用，如数据库查找优化[19，42]，微代码生成[107]，快速指令集仿真[34，93]。

##### 2.5.2 客制化

客制化部分编译代码到特定环境的想法与动态编译密切相关因为环境信息直到运行前不总是有效的。例如，Mitchell 的系统[97] 特殊化算术操作到操作数的运行时类型。当变量的类型改变了，所有的依赖于这个类型的编译代码都会被丢弃掉。因为这个语言不支持用户自定义多态且不是面向对象，这个方案的主要动机是降低解释过程的固定开销和将一些通用的内置操作替换为简单的，特定的代码序列（如，用整型加法替换通用加法）。

相似地，APL 编译器为某些表达式创建特定的代码[80，51，61]。对于这些系统，HP APL 编译器[51]最接近 SELF 使用的客制化技术。HP APL/3000 系统按一条一条语句的方式编译代码。除了执行 APL 特定的优化，编译过的代码被特定化根据特定的操作数类型（维数，每一维的大小，元素类型，存储布局）。这些所谓的”硬“代码比起通用的版本可以更高效地执行因为一个APL操作执行的计算可能会因实际参数类型而有很大差异。为了保持语言的语义，

# 总结

